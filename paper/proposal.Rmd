---
title: "STA302 Final Project Proposal"
subtitle: ""
author: 
  - name: "Ziqi Zhu"
  - name: "Raghav Sinha"
  - name: "Christophe McWatt"
thanks: "Code and data are available at: https://github.com/zzq20010617/sta302Paper"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
date-format: long
abstract: ""
number-sections: true
bibliography: proposal_references.bib
format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(ggplot2)
library(GGally)
library(readr)
library(tibble)
library(knitr)
library(kableExtra)
library(dplyr)
data <- read.csv("../data/analysis_data/analysis_data.csv")
```

# Contributions
We found the dataset together, and seperate the works as follow:
Ziqi: Introduction and data description
Raghav: Ethics discussion and some plot in preliminary result
Christophe: Most of Preliminary results section

# Introduction
The gaming industry has experienced exponential growth in recent years, with millions of players engaging in various games on platforms like Steam. Understanding what influences average playtime in games is crucial for game developers, publishers, and marketers. Average playtime is a key indicator of player engagement and game success, and investigating factors that impact it can provide valuable insights into game design, pricing strategies, and marketing efforts. So our research aims to explore the factors that influence the average playtime of games available on Steam using a dataset we get from Kaggle. Specifically, we will investigate how variables such as price, user ratings, and other game characteristics contribute to player engagement, as measured by playtime.
From some previous papers, we learned that both positive and negative reviews have a significant correlation with playtime, but the effect is more pronounced for positive reviews(@paper1). Another paper found out that game pricing significantly affects player engagement, with lower-priced games generally seeing higher playtime.(@paper2). The third paper did an empirical study that also examined the influence of game reviews on playtime, focusing on how the number and sentiment of reviews can affect player engagement. It concludes that games with more positive reviews see increased playtime, especially if those reviews highlight the gameâ€™s quality(@paper3).
We found this problem suitable for linear regression because it allows us to model the relationship between average playtime (the dependent variable) and various predictors (price, ratings, developer, etc.). This approach helps quantify how each factor influences playtime, enabling a clear understanding of the impact of different game attributes. By fitting a linear regression model, we can determine which factors have statistically significant effects on playtime, providing actionable insights for game developers and marketers.


# Data description
We get the Steam games data(@davis2023steam) from Kaggle. The R programming language (@talia) and packages readr(@readr), httr(@httr), jsonlite(@jsonlite) were used to download the data, dplyr(@dplyr) and lubridate(@lubridate) were used to clean the data. Data was originally gathered from the Steam Store and SteamSpy APIs around May 2019. This table @tbl-cle shows the first 3 entries of cleaned data. We are going to take average_playtime as the response variable, it measures the mean time (in minutes) that players spend on a game, a summary of this variable is shown in @tbl-aveplaytime. This variable captures overall player engagement and serves as a good indicator of how immerse or entertaining a game is. It is suitable for a linear regression model because it is continuous and quantitative. The predictors selected are price, positive ratings, negative ratings, developer, and number of owners. All are numeric except for the number of owners, which is categorical since it represents estimated ranges. Price may influence playtime, as higher costs could lead to longer engagement. Positive ratings and negative ratings are reviews of players of that game and it can only be positive or negative. Positive ratings likely correlate with greater playtime, while negative ratings could indicate the opposite. Developer refers to the development company of the game, which could affect playtime, with established studios often producing longer, high-quality games, but since they are too many developers to fit we are planning to create bins or indicator variables in later phase. Lastly, the number of owners is an estimated number of owners, containing lower and upper bounds (like 20000-50000), it could signal popularity, where more owners may suggest higher average playtime. Summary of numerical predictors can be find in table @tbl-predictor.
```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-cle
#| tbl-cap: "Steam Games Data"
#| tbl-float: false

head(data, 3) %>% 
  kbl("latex") %>%
  kable_styling(latex_options = c("striped", "scale_down")) 
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-aveplaytime
#| fig-pos: "H"

summary_table <- data %>%
  summarise(
    Mean = round(mean(average_playtime, na.rm = TRUE), 2),
    Median = round(median(average_playtime, na.rm = TRUE), 2),
    Std_Dev = round(sd(average_playtime, na.rm = TRUE), 2),
    Min = round(min(average_playtime, na.rm = TRUE), 2),
    Max = round(max(average_playtime, na.rm = TRUE), 2),
  )
kable(summary_table, caption = "Summary of Average Playtime")
```


```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-predictor

predict_summary_table <- data %>%
  summarise(
    mean_price = round(mean(price, na.rm = TRUE), 2),
    median_price = round(median(price, na.rm = TRUE), 2),
    mean_positive_ratings = round(mean(positive_ratings, na.rm = TRUE), 2),
    median_positive_ratings = round(median(positive_ratings, na.rm = TRUE), 2),
    mean_negative_ratings = round(mean(negative_ratings, na.rm = TRUE), 2),
    median_negative_ratings = round(median(negative_ratings, na.rm = TRUE), 2),
  )
kable(predict_summary_table, caption = "Summary of Predictors") %>%
kable_styling(latex_options = c("striped", "scale_down"), font_size = 6) 
```

# Ethics discussion
The Steam Games dataset(@davis2023steam) used in this research is a collected dataset, not simulated, comprising information on over 97,000 games published on the Steam platform. The metadata is comprehensively filled out, including details such as game titles, release dates, genres, and user ratings, which enhances the dataset's usability and reliability. The source of the data is clearly described, originating from the Steam store pages and Steam API, ensuring transparency and traceability. Additionally, the dataset is hosted on Kaggle, a reputable platform for data science and machine learning, and has been vetted and used in existing literature (discussed in the introduction). This widespread use and accessibility suggest that the dataset is well-regarded and trusted by third parties, further validating its credibility through the framework outlined in the ethics module. There are no ethical concerns to report.

# Preliminary results

## Fit multiple linear regression model
```{r}
#| echo: false
#| warning: false
#| message: false

model <- lm(average_playtime ~ price + positive_ratings + negative_ratings + achievements + owners, data=data)
```
## Create Response vs Fitted Scatterplot to check patterns in residuals before further analysis.
```{r}
#| echo: false
#| warning: false
#| message: false
y_hat <- fitted(model)
plot(x = y_hat, y = data$average_playtime, main = "Response vs. Fitted", xlab = "Fitted", ylab = "Average Playtime")
abline(a=0, b=1, lty=2)
```
## Create Pairwise Scatterplots for Predictors to look for multicollinearity
```{r}
#| echo: false
#| warning: false
#| message: false

ggpairs(data[, c(5, 6, 7, 11)]) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
        axis.text.y = element_text(size = 8))

```
## Create Residuals vs Fitted Scatterplot to check Linearity, Uncorrelated Errors, and Constant Variance
```{r}
#| echo: false
#| warning: false
#| message: false
y_value <- resid(model)
x_value <- fitted(model)

plot(x = x_value, y = y_value, main = "Residual vs. Fitted", xlab = "Fitted", ylab = "Residuals")
```

## Create Residuals vs each Quantitative Predictor scatterplot to check Linearity, Uncorrelated Errors, and Constant Variance
```{r}
#| echo: false
#| warning: false
#| message: false
par(mfrow=c(1,4))

plot(x = data$price, y = y_value, main = "Residuals vs. Price", xlab = "Price", ylab = "Residuals")

plot(x = data$positive_ratings, y = y_value, main = "Residuals vs. Positive Ratings", xlab = "Positive Ratings", ylab = "Residuals")

plot(x = data$negative_ratings, y = y_value, main = "Residuals vs. Negative Ratings", xlab = "Negative Ratings", ylab = "Residuals")

plot(x = data$achievements, y = y_value, main = "Residuals vs. Achievements", xlab = "Achievements", ylab = "Residuals")
```
## Create BoxPlot to check assumptions for Categorical Predictors
```{r}
#| echo: false
#| warning: false
#| message: false
par(mfrow=c(1,2))

boxplot(y_value ~ data$developer , main="Residual vs Developer",
xlab="Developer", ylab="Residuals")

boxplot(y_value ~ data$owners , main="Residual vs Owners",
xlab="Owners", ylab="Residuals")
```
## Create Normal QQ Plot to check Normality assumption
```{r}
#| echo: false
#| warning: false
#| message: false
qqnorm(y_value)
qqline(y_value)
```
## Box-Cox Transformation
```{r}
#| echo: false
#| warning: false
#| message: false
library(MASS)
library(caret)

# Define the Box-Cox transformation function
boxcox_transform <- function(x) {
  bc <- BoxCoxTrans(x)
  predict(bc, x)
}

# Apply the transformation to each predictor and the response
bc_average_playtime <- boxcox_transform(data$average_playtime)
bc_price <- boxcox_transform(data$price)
bc_positive_ratings <- boxcox_transform(data$positive_ratings)
bc_negative_ratings <- boxcox_transform(data$negative_ratings)
bc_achievements <- boxcox_transform(data$achievements)
```
## Fitting transformed model
```{r}
#| echo: false
#| warning: false
#| message: false
model_transformed <- lm(bc_average_playtime ~ bc_price + bc_positive_ratings + bc_achievements+ bc_negative_ratings + owners, data=data)
```
## Checking for Multicollinearity
```{r}
#| echo: false
#| warning: false
#| message: false
# install.packages("car")
library(car)
vif(model_transformed)
```
## Fitting Reduced Model
```{r}
#| echo: false
#| warning: false
#| message: false
reduced <- lm(bc_average_playtime ~ bc_price + bc_positive_ratings + bc_achievements + owners, data=data)
summary(reduced)
```
## Generatingn Residual Plots
```{r}
#| echo: false
#| warning: false
#| message: false
par(mfrow = c(2, 2))
plot(reduced)
```
## AIC Model Selection
```{r}
#| echo: false
#| warning: false
#| message: false
step_model <- stepAIC(reduced, direction = "both")
summary(step_model)
```
## ANOVA Comparison between full model and reduced model
```{r}
#| echo: false
#| warning: false
#| message: false
anova(step_model, reduced)
# Conclude that step_model (without bc_achievements is better suited and no significant improvement to model from bc_achievements)
```
```{r}
#| echo: false
#| warning: false
#| message: false
summary(step_model)
```
The four linear regression assumptions to be looked into are linearity, uncorrelated errors, constant error variance, and normality. Since this is a multiple linear regression, we must also check the conditional mean response and predictor conditions. To check the conditional mean response condition, we look at the Response vs. Fitted scatterplot. We see an that the data points are clustered fairly tightly in the bottom left corner of the scatterplot, which satisfies the condition. To check the conditional mean predictors assumption, we must look at the pairwise scatterplots of predictors, in which we see a lack of curves which satisfies this condition as well. When looking at the Residual vs. Fitted scatterplot, we can see a fanning pattern in the shape of a left pointing arrow, which leads to a possible violation of the constant variance assumption. Looking at the Residuals vs. Qualitative Predictor scatterplots suggests a possible violation of both linearity and uncorrelated errors due to the cluster of many points in all three as well as the curves that exist in the positive and negative ratings. Neither of the boxplots appear to suggest any kind of linear assumption violation regarding the categorical predictors. Looking at the Normal QQ Plot, there is some deviation from the diagonal at the extremes that appears to be too significant to ignore. This leads to a normality violation. There being so many possible assumption violations makes sense due to the nature of the data. For example, the violation of the uncorrelated errors assumption is valid because the predictors would depend on one another if even slightly (i.e. price and developer). The results of this preliminary model are fairly similar to the results in the literature as similar errors and violated assumptions were noted. Transformations in order to mitigate these violations will be vital to maintain the stability of the normal model.
\newpage

# References
